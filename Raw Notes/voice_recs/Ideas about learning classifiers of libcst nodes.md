L'idea di cui voglio parlare è sostanzialmente un progetto di un primo paper, ce n'è un secondo di cui prenderò delle note successivamente, sullo studio della capacità di language model in generale e più nello specifico di embedding models, di comprendere il codice python. Nello specifico l'idea è di utilizzare libcst per creare dei concrete syntax trees del codice e utilizzarli per... creare delle label dei tipi di nodi che vengono utilizzati all'interno di uno snippet di codice python. L'obiettivo dello studio è vedere se siamo in grado di creare dei modelli predittivi che dagli embedding prevedono le label dei nodi sintatici. Quindi, ribadendo, l'idea è che possiamo utilizzare il concrete syntax tree per creare delle etichette associate degli snippet di codice python che sono una rappresentazione discreta del contenuto sintattico del codice e imparando un modello predittivo che prevede utilizzando la rappresentazione del codice in stringa, embeddata da un language model per prevedere l'etichetta sintattica, e che questa sia una misura della capacità del language model di rappresentare e comprendere il codice in termini funzionali. 

Quindi, il primo step è creare una collezione dataset, fatto da una collezione di repository di codice Python, e parsare il codice Python utilizzando l'IBCST in classi e metodi. Dopodiché, probabilmente, conviene separare le due rappresentazioni, la rappresentazione in classi e la rappresentazione in metodi, che avranno in linea di massima delle lunghezze e distribuzioni molto diverse di nodi sintatici. 

Se vogliamo utilizzare molteplici modelli closed source via API non possiamo permetterci un dataset troppo grande e probabilmente stare tra un milione e 10 milioni di token è ideale. Questo potrebbe essere un po' restrittivo in termini di dimensione del dataset quindi dobbiamo vedere un attimo le quantità. In linea di massima 100 milioni di token sono all'incirca 2 dollari per modello per small e 12 per large. utilizzare una dimensione maggiore vorrebbe dire iniziare a spendere fino a potenzialmente un centinaio di euro con gli embedding più grandi per ognuna e pensano di fare 4, 5, 6, 7 comparison potremmo stare nell'ordine del migliaio di euro se riuscissimo a stare sotto 100 euro di esperimenti per iniziare sarebbe sicuramente buono oggettivamente avere un miliardo di token e rilasciare un miliardo di token python embeddati con tutti i vari embedder potrebbe essere un'ottima soluzione 

dato che vorremmo usare alcuni modelli da HugginFace e, di quelli davvero open source, il processo potrebbe prendere abbastanza, soprattutto se vogliamo arrivare a un miliardo. Quindi prima di tutto dobbiamo capire come utilizzare le GPU locali al massimo e eventualmente capire, probabilmente utilizzando modal, come scalare il processo. Questo comunque è molto buono perché sarebbe parte di un contributo che dovremmo fare a Cynde.

Il secondo step invece, dopo aver fatto questi dataset, sarà dare un attimo un occhio alla distribuzione dei nodi, vedere se sono interessanti oppure no. Penso che probabilmente vorremmo provare a classificare il dataset, scusa, il rettifico, il pacchetto di provenienza dallo snippet di codice, e penso, utilizzando gli embeddings ovviamente, e penso che vorremmo anche usare per lo stesso task come features alternative gli istogrammi di nodi sintattici al posto della rappresentazione in stringa del codice, e penso che probabilmente vorremmo anche utilizzare l'embedding della versione stringa del concrete syntax tree dello snippet. 

Quindi abbiamo detto che per ogni snippet di codice abbiamo molteplici rappresentazioni. La prima è la rappresentazione testuale del codice della stringa che definisce lo snippet di codice. La seconda è la rappresentazione in stringa dell'albero sintattico. E' l'equivalente a quello snippet di codice come output da libcst. E terzo è la rappresentazione in termini di istogramma di nodi dell'albero sintattico. Quindi quest'ultima è una rappresentazione categorica oppure potremmo pensarla come un vettore visto che sono molteplici categorie. Le prime due rappresentazioni in stringa possono essere trasformate in vettori utilizzando dei language model o degli embedding model Grazie. 

Ok, finalmente invece nel terzo step che risulta essere un po' l'analisi conclusiva del paper, partirei di base dalla capacità dei vari embedding models di classificare, diciamo, della possibilità di imparare dei classificatori dai vari embedding models che permette di mappare dagli snippet allo spazio categorico dell'albero sintattico. La conclusione qui sarebbe di creare un rank tra gli embedders rispetto a quelli che hanno una capacità all'interno, durante il mapping vettoriale, normalmente considerato, tra virgolette, semantico, di mantenere memoria della sintassi del codice embeddato. Questo è ovviamente anche legato all'idea che la semantica e la sintassi di un codice sono molto legate, a differenza del linguaggio naturale normale dove la relazione e' piu offuscata.






