[[Cynde]][[LLM]][[Transcripts]]
Cinde is the main project on which I'm working now and the general idea is that most of the modern development around large language modeling technologies are around SDLs and class-based, object-oriented wrapping of APIs that kind of complicates the overall prompting and scientific utilization of the tool. So the main challenge I faced over the last year of working with those technologies and consulting around it was how to handle the state and how to properly pass it. So the main challenge I faced over the last year of working with those technologies and consulting around it was how to handle the state and how to properly pass it. So the main challenge I faced over the last year of working with those technologies and consulting around it was how to properly pass it. So the main challenge I faced over the last year of working with those technologies and consulting around it was how to properly pass it. parallelize in an efficient way the language model and/or embedding operations and mostly how to validate them. 

Simultaneously working with Python in not even large scale, speaking of the terabyte, but on the medium to large scale with respect to data, so having data set with from the thousands to the small millions of rows becomes very complicated to handle states if the states are separated in classes that are executed in the best case scenario with some sort of async processing over the data. And my main, I always ended up then whenever one goes back to some other framework needs to pipe the LLM processes into something else to become quite an issue and having infinite for loops. So I had a lot of dictionary comprehension of some awkward ashmap abstraction that I ended up developing through the process. I feel like my main solution for the time being is that of using Polars as in memory and potentially through lazy queries on disk data structure that also act as an orchestrator for multi-threaded operations over the data. Cinde wants to be pretty much my tentative of simplifying my life around large language models/embeddings/traditional data science. And the last component that has not been mentioned is the data structure. The first thing I want to mention is how to validate things. There are a lot of choices involved with the language models and a lot of them can only be attempted through some sort of vibe check unless you lock yourself in another DSL/SDR like DSPy. The second thing is to choose what is the best embedding, the best structure of extraction, what is the best prompt. The only proper answer that I have is to use predictive models. The idea is that there must be a predictive model task that is set up such that the input of the model is correct. The predictive task is the output that is a function of the uncertain choices such that we can measure the uncertain choices by how they influence the out-of-sample performance in the predictive task. 


The most direct functionalities that are brought in by SINDE is the ability to embed automatically polar... actually let me take a step back, what happened is that... sorry for the silence... so the main idea is whenever you work with data set in traditional machine learning you are mostly allowed to work with numerical or categorical data. In a way or the other both representations are mapped to a vector space where the classifier... where an hyperplane is used to define a classifier. Recently like the field of multimodal machine learning developed ad hoc techniques for embedding, vectorizing specific types of data. Typically these techniques require pre training, feature extractors, neural network or some other sort of encoding function that allows to map unstructured data to vectors. In SINDE we take... we make use of these specifically for string data making use of two core operators: embedders, so encoder language transformer model, encoders only transformers model that map string to a vector, and language models that map a string to another string. So specifically we are dealing with chat-instructed language models. The further addition that we add is that string can be seen as structured objects or entities or dictionaries or hash maps through the JSON string abstraction. When using the JSON string abstraction we are able in a way to see our string to string operations as some entity to entity, some categorical operations over an object-oriented representation of our reality. 

The easier way to work in Python with JSON strings and to map between strings and objects is Pydantic. With Pydantic we can validate models and we can validate strings and we can define other than using Python typeins we can write further custom validators that can be used to define any logic for validation that ensure safety and stability of our entity-based system.  Connecting the two things to language model, the idea is that if we are able to constrain language model to output a string that has a specific structure, and this is done using packages like in structure or outlines that interact with language model APIs to control the sampling process such that the sampling process of the language model resembles others to a state machine that is defined out of a JSON template given by the user. When this happens, we can think that we are able to extend our machine learning capabilities and our vectorization. So, we can think that we are able to extend our machine learning capabilities and our vectorization. to discrete categories using pedantic models to parse a string defining a category and outputting new pedantic objects as output.  Unfortunately the previous part has not been transcribed properly. So what I was saying is that we develop in SIN the ability to map data type, data columns in POLAR that are strings to categories through predictive models, data columns that are strings to vectors through embedding models, strings through strings through language models, strings to categories through structured extraction of language models. 

Ok, the document above is a mixture of my own transcribed recording with a to be honest kind of bad recognition model and your own summarization of what I said. Now please fully summarize the, no do not summarize, fully rewrite the text following my talking style and be exhaustive but have a better logical order and be inclusive. Do not worry about writing too much. 
rewrite removing repetitions but mantain the verbose prose and logical evolution of the concept to my personal self conversatin but mantaining the same prose using the correct spelling Cynde, Pydantic, Polars. 

